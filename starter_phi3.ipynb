{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506fab2a-a50c-42bd-a106-c83a9d2828ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as minsearch.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Remove the file if it exists\n",
    "file_path = 'minsearch.py'\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "\n",
    "# Download the new file from internet\n",
    "url = 'https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"File downloaded and saved as {file_path}\")\n",
    "else:\n",
    "    print(\"Failed to download the file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac947de-effd-4b61-8792-a6d7a133f347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x248162948e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import minsearch\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f087272-b44d-4738-9ea2-175ec63a058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "742ab881-499a-4675-83c4-2013ea1377b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='phi3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe8bff3e-b672-42be-866b-f2d9bb217106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "988ece59-951a-4b32-ba3f-cb8efb66a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# to know the port number type \"ollama start\" in console\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b9e7114-7853-496c-b94b-53f80d7504f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' To create an automated script to perform a basic system check and generate a report, I\\'ll be using Python along with some of its libraries like `os`, `psutil` for monitoring the system processes, and reporting via simple text output. Below you will find a very simplistic example:\\n\\n```python\\nimport os\\nimport sys\\nimport psutil\\n\\n# Define functions to check various aspects of your computer\\'s health & status\\ndef get_cpu_load():\\n    return psutil.getloadavg()[0]  # Get average load for the last 1 minute, excluding idle process(es) and system processes (soil not reported).\\n\\ndef is_memory_overheating(max_percentage=85):\\n    mem = psutil.virtual_memory()\\n    return round((mem.used/mem.total)*100, 2) > max_percentage   # Check if memory usage exceeds a threshold (%) and returns True or False accordingly for overheating indication\\n    \\ndef is_disk_space_low(threshold=35):  # Threshhold to check low disk space situation in percent. e.g., If less than the free hard drive, it means underflowed!  \\n    result = psutil.df()[4:]\\n    used_size = sum([int(x[\\'used\\']) for x in result]) / (result[-1][0] + 1) * 100 # Calculate percentage of disk space free    \\n    return round(free, 2) < threshold\\n    \\ndef is_cpu_temperature_high():  \\n    temp = psutil.sensors_battery().current_temp / 100       # Get CPU temperature in degree Celsius (approx). Divide by 10 to get Fahrenheit scale, which we expect most of you might be using on PCs!        \\n     return round(temp,2) > 75    # The average human body temp is approximately around 36.8Â°C; So above that temperature means its overheating situation for CPU in general context (not specific to Intel or AMD processors).          \\n       \\ndef generate_report():    \\n    cpu = get_cpu_load()     \\n    mem = psutil.virtual_memory().percent  # Check Memory usage percentage        \\n    disk_space = is_disk_space_low(threshold=35)  \\n    temp = \"high\" if is_cpu_temperature_high() else (\"okay\" if not cpu and not mem and not disk_space else str())       \\n     return f\"CPU Load: {round(cpu, 2)}%, Memory Usage Percentage : {mem}% , Disk Space Left Available in GBs (Low/Ok):{str(disk_space)}, Current CPU Temperature Status:{temp}\"   # Return the report as string\\n      \\n# Main method starts here for script execution.        \\ndef main():    \\n    print(\"Running System Check Test:\") \\n    sys.stdout.write(generate_report()+\"\\\\n\")     # Generate and display Report to User using Print Statement of Python Standard Library!            \\n                     \\nif __name__ == \\'__main__0\\':        \\n        main()      \\n```\\nThis script is a simplistic model that you can extend upon for more detailed reports or monitoring. It only considers CPU load, memory usage percentage, disk space and current temperature of the system as indicators to monitor health & status changes over time by executing it frequently using task scheduling tools available in your operating systems (Windows Task Scheduler on Windows).\\nNote: This script does not guarantee accuracy for all situations or hardware configurations. Always consult with professional IT resources when needed!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('write this is a test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c7a95-5e28-49ee-9401-fb38d97a34fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
